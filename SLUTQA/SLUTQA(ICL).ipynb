{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aabb172-1017-4540-8f3a-7b544c5837b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipywidgets import FloatProgress\n",
    "import re\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "import json\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import re\n",
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "from rank_bm25 import BM25Okapi\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aa9c11-ea83-46a0-87bb-2b56eff070f5",
   "metadata": {},
   "source": [
    "#### Please modify this section to include a usable API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3db9478-aeb3-4134-83cc-982a318e93d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_base_url = \"http://change me\"\n",
    "model_name = 'change me'\n",
    "api_key = 'change me'\n",
    "llm = ChatOpenAI(model_name=model_name, openai_api_key=api_key, base_url=custom_base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f8feed-fdac-4862-ae88-d03977c9765a",
   "metadata": {},
   "source": [
    "# ICL for SLU prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f8ce69-19bb-4e78-a1cb-e18b6e61120c",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = '../dataset/train.json'\n",
    "with open(json_file, 'r', encoding='utf-8') as f:\n",
    "    datas = json.load(f)\n",
    "all_intent  = []\n",
    "for data in datas:\n",
    "    intent = data['intent']\n",
    "    if intent not in all_intent:\n",
    "        all_intent.append(intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2474d9-f503-474a-85df-133abea6d5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = all_intent\n",
    "tokenized_corpus = [list(jieba.cut_for_search(doc)) for doc in corpus]\n",
    "# 构建索引\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11f712f-3798-4b0c-b7e0-366aef4d9e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_path = './prompts/SLU_prompt.json'\n",
    "with open(template_path, 'r', encoding='utf-8') as f:\n",
    "    template = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b780ae1a-fcf8-4f08-9fac-684c62c708ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_intent_and_slots(text):\n",
    "    # Regular expression patterns to extract intent and slots\n",
    "    intent_pattern = r\"intent[:>)]?\\s*(.*?)(?=[<\\(]_?slots_?[>\\)])\"\n",
    "    slots_pattern = r\"[<\\(]_?slots_?[>\\)]\\s*(\\[.*?\\])\"\n",
    "    #intent_pattern = r\"intent[:>)]?\\s*([^,]+?)(?=[<\\(]_?slots_?[:>)]?)\"\n",
    "    #slots_pattern = r\"[<\\(]_?slots_?[:>)]?\\s*(\\[.*?\\])\"\n",
    "\n",
    "    # Extracting intent\n",
    "    intent_match = re.search(intent_pattern, text)\n",
    "    if intent_match:\n",
    "        intent = intent_match.group(1).strip()\n",
    "    else:\n",
    "        intent = None\n",
    "\n",
    "    # Extracting slots\n",
    "    slots_match = re.search(slots_pattern, text)\n",
    "    if slots_match:\n",
    "        slots_str = slots_match.group(1)\n",
    "        try:\n",
    "            slots_list = ast.literal_eval(slots_str)  # Safely evaluates the string as a list\n",
    "        except (SyntaxError, ValueError) as e:\n",
    "            print(f\"Error parsing slots: {e}\")\n",
    "            slots_list = None\n",
    "    else:\n",
    "        slots_list = None\n",
    "\n",
    "    return intent, slots_list\n",
    "\n",
    "def slots_to_dict(slots_list):\n",
    "    slots_dict = {}\n",
    "    if slots_list:\n",
    "        for slot in slots_list:\n",
    "            key, value = slot.split(':')\n",
    "            slots_dict[key.strip()] = value.strip()\n",
    "    return slots_dict\n",
    "\n",
    "\n",
    "\n",
    "def extract_slu(text: dict):\n",
    "    pred = text.lower().strip()\n",
    "    pred = pred.replace('_', '')\n",
    "    pred = pred.replace('\\n', '')\n",
    "    if 'intent:' in pred:\n",
    "        pred = pred.replace('intent:', '<intent>')\n",
    "    if 'slots:' in pred:\n",
    "        pred = pred.replace('slots:', '<slots>')\n",
    "    if ' slots ' in pred:\n",
    "        pred = pred.replace(' slots ', '<slots>')\n",
    "    if '」' in pred: \n",
    "        pred = pred.replace('」', '\\']')\n",
    "    intent, slots = extract_intent_and_slots(pred)\n",
    "    intent = bm25.get_top_n(list(jieba.cut_for_search(intent)), corpus, n=1)\n",
    "    if intent != None and slots != None:\n",
    "        extract_intent = intent\n",
    "        extract__slots = slots\n",
    "    else:\n",
    "        print(f'This：{pred}')\n",
    "        extract_intent = 'error'\n",
    "        extract__slots = text\n",
    "    return extract_intent, extract__slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c444e650-268a-4ef0-a125-34972358cfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert slots into keywords\n",
    "def restore_keywords_from_query(query, slots):\n",
    "    keywords = []\n",
    "    current_tokens = []\n",
    "    current_label = None\n",
    "    query = list(query)\n",
    "    if isinstance(slots, str):\n",
    "        slots = slots.split(' ')\n",
    "    if slots[0] == '[CLS]':\n",
    "        slots = slots[1:-1]\n",
    "\n",
    "    for token, slot in zip(query, slots):\n",
    "        if slot.startswith('B-'):\n",
    "            if current_tokens:\n",
    "                keywords.append((''.join(current_tokens), current_label))\n",
    "                current_tokens = []\n",
    "            current_label = slot[2:]\n",
    "            current_tokens.append(token)\n",
    "        elif slot.startswith('I-') and current_label == slot[2:]:\n",
    "            current_tokens.append(token)\n",
    "        else:\n",
    "            if current_tokens:\n",
    "                keywords.append((''.join(current_tokens), current_label))\n",
    "                current_tokens = []\n",
    "                current_label = None\n",
    "\n",
    "    if current_tokens:\n",
    "        keywords.append((''.join(current_tokens), current_label))\n",
    "    keyword_pair = []\n",
    "    for keyword in keywords:\n",
    "        if keyword[-1] == 'city':\n",
    "            keyword_pair.append(f'城市:{keyword[0]}')\n",
    "        elif keyword[-1] == 'district':\n",
    "            keyword_pair.append(f'区域:{keyword[0]}')\n",
    "        elif keyword[-1] == 'development':\n",
    "            keyword_pair.append(f'项目名称:{keyword[0]}')\n",
    "        elif keyword[-1] == 'company':\n",
    "            keyword_pair.append(f'企业名称:{keyword[0]}')\n",
    "        elif keyword[-1] == 'year':\n",
    "            keyword_pair.append(f'年份:{keyword[0]}')\n",
    "        elif keyword[-1] == 'month':\n",
    "            keyword_pair.append(f'月份:{keyword[0]}')\n",
    "        elif keyword[-1] == 'land':\n",
    "            keyword_pair.append(f'地块名称:{keyword[0]}')\n",
    "\n",
    "    return keyword_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fade9c-9016-4434-8942-4b7b77b245f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "json_file = '../dataset/test.json'\n",
    "with open(json_file, 'r', encoding='utf-8') as f:\n",
    "    datas = json.load(f)\n",
    "\n",
    "for data in tqdm(datas):\n",
    "    query = data['query']\n",
    "    slots = data[\"slots\"].split(',')\n",
    "    data['true_slots_name'] = restore_keywords_from_query(query, slots)\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    chain = prompt | llm\n",
    "    key_words = restore_keywords_from_query(query, slots)\n",
    "    response = chain.invoke({\"query\":query})\n",
    "    # print(response.content)\n",
    "    data['ICL_pred_intent'], data['ICL_pred_slots'] = extract_slu(response.content)\n",
    "\n",
    "save_json_file = './results/test-with-ICL_pred_intent+slots.json'\n",
    "with open(save_json_file, 'w', encoding='utf-8') as file:\n",
    "    json.dump(datas, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa0bb34-ecd0-4b81-891a-a5b07af61067",
   "metadata": {},
   "source": [
    "### Calculate SLU prediction metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abef23f4-cb4e-4b07-8f29-f14917711f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_compute(trues: list, preds: list):\n",
    "    if len(trues) != len(preds):\n",
    "        return 'Input lengthes not equal!'\n",
    "    precision = 0\n",
    "    precision_all = 0\n",
    "    recall = 0\n",
    "    recall_all = 0\n",
    "    for true_label, pred_label in zip(trues, preds):\n",
    "        if isinstance(true_label, type('')):\n",
    "            true_label = [true_label]\n",
    "        if isinstance(pred_label, type('')):\n",
    "            pred_label = [pred_label]\n",
    "        for pred in pred_label:\n",
    "            if pred in true_label:\n",
    "                precision += 1\n",
    "            precision_all += 1\n",
    "        for true in true_label:\n",
    "            if true in pred_label:\n",
    "                recall += 1\n",
    "            recall_all += 1\n",
    "    P = precision/precision_all\n",
    "    R = recall/recall_all\n",
    "    F1 = 2 * P * R / (P + R)\n",
    "    return P, R, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68790b96-6ccc-47f9-a194-a64a754d3321",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas_saved_file = './results/test-with-ICL_pred_intent+slots.json'\n",
    "with open(datas_saved_file, 'r', encoding='utf-8') as f:\n",
    "    datas = json.load(f)\n",
    "predicts = []\n",
    "trues = []\n",
    "\n",
    "for data in datas:\n",
    "    trues.append(data['intent'])\n",
    "    try:\n",
    "        predicts.append(data['ICL_pred_intent'])\n",
    "    except:\n",
    "        print(data)\n",
    "\n",
    "print('ICL Intent prediction results')\n",
    "metric_compute(trues, predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c149f1-a597-4e07-94f7-1a20e6561811",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas_saved_file = './results/test-with-ICL_pred_intent+slots.json'\n",
    "with open(datas_saved_file, 'r', encoding='utf-8') as f:\n",
    "    datas = json.load(f)\n",
    "predicts = []\n",
    "trues = []\n",
    "\n",
    "for data in datas:\n",
    "    trues.append(data['true_slots_name'])\n",
    "    try:\n",
    "        predicts.append(data['ICL_pred_slots'])\n",
    "    except:\n",
    "        print(data)\n",
    "\n",
    "print('ICL Slots prediction results')\n",
    "metric_compute(trues, predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab4f7ea-65e5-47ca-979a-05e342f118ac",
   "metadata": {},
   "source": [
    "# SR module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5468c16d-e289-4c63-83e5-b4f19351c646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the generated table names in a JSON file.\n",
    "class PredictResultStorage:\n",
    "    def __init__(self, file_name='testdata.json'):\n",
    "        self.current_data = {}\n",
    "        self.file_name = file_name\n",
    "\n",
    "    def set_predict_tabel_name(self, predict_tabel_name):\n",
    "        self.current_data[\"predict_tabel_name\"] = predict_tabel_name\n",
    "        \n",
    "    def set_true_tabel_name(self, true_tabel_name):\n",
    "        self.current_data[\"true_tabel_name\"] = true_tabel_name\n",
    "\n",
    "    def set_uuid(self, uuid):\n",
    "        self.current_data[\"uuid\"] = uuid\n",
    "\n",
    "    def save_data(self):\n",
    "        if os.path.exists(self.file_name):\n",
    "            with open(self.file_name, 'r+') as f:\n",
    "                data = json.load(f)\n",
    "                data.append(self.current_data)\n",
    "                f.seek(0)\n",
    "                json.dump(data, f, indent=4)\n",
    "        else:\n",
    "            with open(self.file_name, 'w') as f:\n",
    "                json.dump([self.current_data], f, indent=4)\n",
    "        # Clear current_data to prepare for storing the next piece of data.\n",
    "        self.current_data = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06448238-34c1-493c-b405-dca3a09a9d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read templates\n",
    "prompt_file_name = './prompts/retrival_prompt.json'\n",
    "with open(prompt_file_name, 'r', encoding='utf-8') as f:\n",
    "    templates = json.load(f)\n",
    "#templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b586f31-b57e-4896-9054-bf598c4fcb45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_saved_file = './results/SLUTQA(ICL)-SR-module-result.json'\n",
    "json_file = './results/test-with-ICL_pred_intent+slots.json'\n",
    "with open(json_file, 'r', encoding='utf-8') as f:\n",
    "    datas = json.load(f)\n",
    "for data in tqdm(datas):\n",
    "    try:\n",
    "        query = data['query']\n",
    "        intent = data['ICL_pred_intent'][0]\n",
    "        slots = data['ICL_pred_slots']\n",
    "        prompt = ChatPromptTemplate.from_template(templates[intent])\n",
    "        chain = prompt | llm\n",
    "        response = chain.invoke({\"input_query\":query,\"intent\":intent, \"slots\":slots})\n",
    "        data['predict_tabel_caption'] = response.content\n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"An unexpected interruption occurred at record {i}.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8654bc84-fad6-40bb-b3d4-9e2e017442f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the table names and store them as a vector in memory.\n",
    "table_names_file = './table_names.json'\n",
    "with open(table_names_file, 'r', encoding='utf-8') as f:\n",
    "    name_data = json.load(f)\n",
    "# Corpus\n",
    "corpus = name_data\n",
    "tokenized_corpus = [list(jieba.cut_for_search(doc)) for doc in corpus]\n",
    "# Build the index\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aaf1f6-12e2-49e4-968c-592132558a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = []\n",
    "bm_25s = []\n",
    "trues = []\n",
    "\n",
    "for data in tqdm(datas):\n",
    "    # Perform preliminary cleaning on content generated by the LLM\n",
    "    if '：' in data['predict_tabel_caption'] or ':' in data['predict_tabel_caption']:\n",
    "        #print(data['predict_tabel_name'])\n",
    "        if '：' in data['predict_tabel_caption']:\n",
    "            idx = data['predict_tabel_caption'].rfind('：')\n",
    "        if ':' in data['predict_tabel_caption']:\n",
    "            idx = data['predict_tabel_caption'].rfind(':')\n",
    "        data['predict_tabel_caption'] = data['predict_tabel_caption'][idx+1:]\n",
    "    if ',' in data['predict_tabel_caption'] and '[' in data['predict_tabel_caption']:\n",
    "        #print(data['predict_tabel_name'])\n",
    "        #print('%%%%%%%%%%')\n",
    "        predict = data['predict_tabel_caption'].split(',')\n",
    "        for pred in predict:\n",
    "            pred = pred.replace(\"[\", \"\")\n",
    "            pred = pred.replace(\"]\", \"\")\n",
    "            pred = pred.replace(\"'\", \"\")\n",
    "            pred = pred.replace('\"', '')\n",
    "    else:\n",
    "        predict = data['predict_tabel_caption']\n",
    "        predict = predict.strip(\"[]'\\\"\")\n",
    "        if ',' in predict:\n",
    "            predict = predict.split(',')\n",
    "    # Remove the spaces\n",
    "    if isinstance(predict, type([])):\n",
    "        bm_25 = predict.copy()\n",
    "        for i,pred in enumerate(predict):\n",
    "            pred = pred.replace(\" \", \"\")\n",
    "            pred = pred.replace(\"[\", \"\")\n",
    "            pred = pred.replace(\"]\", \"\")\n",
    "            pred = pred.replace('\\\\', \"\")\n",
    "            pred = pred.replace(\"\\\"\", \"\")\n",
    "            pred = pred.replace(\"\\'\", \"\")\n",
    "            pred = pred.replace(\"\\n\", \"\")\n",
    "            predict[i] = pred\n",
    "            # result = retriever.invoke(pred)\n",
    "            # Retrieve BM25 matching results\n",
    "            tokenized_query = list(jieba.cut_for_search(pred))\n",
    "            result = bm25.get_top_n(tokenized_query, corpus, n=1)\n",
    "            # result = [doc.page_content for doc in result]\n",
    "            bm_25[i] = result[0]\n",
    "    if isinstance(predict, type([])):\n",
    "        predict = list(set(predict))\n",
    "        bm_25 = list(set(bm_25))\n",
    "            \n",
    "    elif isinstance(predict, type('')):\n",
    "        pred = predict\n",
    "        pred = pred.replace(\" \", \"\")\n",
    "        pred = pred.replace(\"[\", \"\")\n",
    "        pred = pred.replace(\"]\", \"\")\n",
    "        pred = pred.replace('\\\\', \"\")\n",
    "        pred = pred.replace(\"\\\"\", \"\")\n",
    "        pred = pred.replace(\"\\'\", \"\")\n",
    "        pred = pred.replace(\"\\n\", \"\")\n",
    "        predict = pred\n",
    "        #result = retriever.invoke(pred)\n",
    "        tokenized_query = list(jieba.cut_for_search(pred))\n",
    "        result = bm25.get_top_n(tokenized_query, corpus, n=1)\n",
    "        # result = [doc.page_content for doc in result]\n",
    "        bm_25 = result[0]\n",
    "    # Extract Chinese characters and create a new list\n",
    "    #predict = [re.sub(r'[^\\w\\s\\u4e00-\\u9fff]', '', s) for s in predict]\n",
    "    predicts.append(predict)\n",
    "    bm_25s.append(bm_25)\n",
    "    true = data['table_caption_label']\n",
    "    trues.append(true)\n",
    "    data['bm25_pred_tabel_caption'] = bm_25\n",
    "print(f'tabel_caption score：{metric_compute(trues, bm_25s)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33a4235-7788-4f87-b106-11be8c8ab10b",
   "metadata": {},
   "source": [
    "# SFA module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bedb368-36b0-47f2-9bd8-180709c6dee5",
   "metadata": {},
   "source": [
    "### Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a6d1ec-442d-4839-8363-402cb8f70e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './prompts/first_prompts.json'\n",
    "with open(file_name, 'r', encoding='utf-8') as f:\n",
    "    first_templates = json.load(f)\n",
    "\n",
    "\n",
    "file_name = './prompts/second_prompts.json'\n",
    "with open(file_name, 'r', encoding='utf-8') as f:\n",
    "    second_templates = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb4afd0-b25f-4e4d-bf91-9e588765dfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_tables_json_file = '../database/markdown_tables/all_markdown_table.json'\n",
    "with open(md_tables_json_file, 'r', encoding='utf-8') as f:\n",
    "    md_table_datas = json.load(f)\n",
    "\n",
    "\n",
    "for data in datas:\n",
    "    names = data['bm25_pred_tabel_caption']\n",
    "    if isinstance(names, type('')):\n",
    "        names = [names]\n",
    "    all_table = ''\n",
    "    for name in names:\n",
    "        for md_table_data in md_table_datas:\n",
    "            if md_table_data['table_name'] == name:\n",
    "                table = md_table_data['markdown_table']\n",
    "                all_table = all_table + ' ' + table\n",
    "    data['pred_markdown_table'] = all_table[1:]\n",
    "\n",
    "for data in tqdm(datas):\n",
    "    try:\n",
    "        query = data['query']\n",
    "        intent = data['ICL_pred_intent'][0]\n",
    "        template1 = first_templates[intent]\n",
    "        template2 = second_templates[intent]\n",
    "        prompt1 = ChatPromptTemplate.from_template(template1)\n",
    "        chain1 = prompt1 | llm\n",
    "        prompt2 = ChatPromptTemplate.from_template(template2)\n",
    "        chain2 = prompt2 | llm\n",
    "        if '+' in intent:\n",
    "            intent = intent.split('+')\n",
    "        else:\n",
    "            intent = [intent]\n",
    "        slots = data['ICL_pred_slots']\n",
    "        input_markdown_table = data[\"pred_markdown_table\"]\n",
    "        \n",
    "        response1 = chain1.invoke({\"input_query\":query,\"intent\":intent,\"slots\":slots,\"table\":input_markdown_table})\n",
    "        # print(response.content)\n",
    "        simple_table = response1.content\n",
    "        response2 = chain2.invoke({\"input_query\":query,\"intent\":intent,\"slots\":slots,\"table\":simple_table})\n",
    "        data['predict_markdown_answer'] = response2.content\n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"An unexpected interruption occurred at record {i}.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac816eea-7797-4293-8bbb-7b6af25e7e5d",
   "metadata": {},
   "source": [
    "## Calculate metrics for Markdown results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6ba9bc-a0d6-419f-a494-192bb408c743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import json\n",
    "import re\n",
    "import argparse\n",
    "from collections import Counter, defaultdict\n",
    "from rouge_score import rouge_scorer, scoring\n",
    "from datasets import load_from_disk\n",
    "from evaluate import load as evaluate_load\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4d4e7b-7827-49a9-a44f-d46328b1642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rows_columns_cells(line):\n",
    "    line=line.lower()\n",
    "    if \"col :\" in line:\n",
    "        line=line.split(\"col :\")[1].strip()\n",
    "    lines=re.split(\"\\s+row\\s+[0-9]+\\s+:\\s+\",line)\n",
    "    rows=[\" | \".join([cell.strip() for cell in row.split(\"|\")]) for row in lines[1:]]\n",
    "    cells=[cell.strip() for row in lines[1:] for cell in row.split(\"|\")]\n",
    "    columns=[\" | \".join([elem.strip() for elem in elems]) for elems in list(zip(*[row.split(\" | \") for row in lines]))]\n",
    "    return rows, columns,cells\n",
    "\n",
    "def get_correct_total_prediction(target_str, pred_str):\n",
    "    target_rows, target_columns, target_cells = get_rows_columns_cells(target_str)\n",
    "    prediction_rows, prediction_columns, prediction_cells = get_rows_columns_cells(pred_str)\n",
    "    common_rows = Counter(target_rows) & Counter(prediction_rows)\n",
    "    common_rows = list(common_rows.elements())\n",
    "    common_columns = Counter(target_columns) & Counter(prediction_columns)\n",
    "    common_columns = list(common_columns.elements())\n",
    "    common_cells = Counter(target_cells) & Counter(prediction_cells)\n",
    "    common_cells = list(common_cells.elements())\n",
    "    return {\"target_rows\":target_rows,\n",
    "          \"target_columns\":target_columns,\n",
    "          \"target_cells\":target_cells,\n",
    "          \"pred_rows\":prediction_rows,\n",
    "          \"pred_columns\":prediction_columns,\n",
    "          \"pred_cells\":prediction_cells,\n",
    "          \"correct_rows\":common_rows,\n",
    "          \"correct_columns\":common_columns,\n",
    "          \"correct_cells\":common_cells}\n",
    "\n",
    "def compute_result(results: list):\n",
    "    total_columns_in_dataset = 0\n",
    "    total_rows_in_dataset = 0\n",
    "    total_cells_in_dataset = 0\n",
    "    total_correct_rows = 0\n",
    "    total_correct_columns = 0\n",
    "    total_correct_cells = 0\n",
    "    total_prediced_rows_in_dataset = 0\n",
    "    total_predicted_columns_in_dataset = 0\n",
    "    total_predicted_cells_in_dataset = 0\n",
    "    preds = []\n",
    "    trues = []\n",
    "    for result in results:\n",
    "        true = result['markdown_answer']\n",
    "        pred = result['predict_markdown_answer']\n",
    "        trues.append(true)\n",
    "        preds.append(pred)\n",
    "        statistics = get_correct_total_prediction(true, pred)\n",
    "        total_columns_in_dataset += len(statistics['target_columns'])\n",
    "        total_rows_in_dataset += len(statistics['target_rows'])\n",
    "        total_cells_in_dataset += len(statistics['target_cells'])\n",
    "        total_correct_columns += len(statistics['correct_columns'])\n",
    "        total_correct_rows += len(statistics['correct_rows'])\n",
    "        total_correct_cells += len(statistics['correct_cells'])\n",
    "        total_prediced_rows_in_dataset += len(statistics['pred_rows'])\n",
    "        total_predicted_columns_in_dataset += len(statistics['pred_columns'])\n",
    "        total_predicted_cells_in_dataset += len(statistics['pred_cells'])\n",
    "    \n",
    "    exact_match_metric = evaluate_load(\"exact_match\")\n",
    "    row_precision = total_correct_rows / total_prediced_rows_in_dataset\n",
    "    row_recall = total_correct_rows / total_rows_in_dataset\n",
    "    row_f1 = (2*row_precision*row_recall)/(row_precision+row_recall)\n",
    "    exact_match_score = exact_match_metric.compute(predictions=preds, references=trues)['exact_match']\n",
    "    column_precision = total_correct_columns / total_predicted_columns_in_dataset\n",
    "    column_recall = total_correct_columns / total_columns_in_dataset\n",
    "    column_f1 = (2*column_precision*column_recall)/(column_precision+column_recall)\n",
    "    cell_precision = total_correct_cells / total_predicted_cells_in_dataset\n",
    "    cell_recall = total_correct_cells / total_cells_in_dataset\n",
    "    cell_f1 = (2*cell_precision*cell_recall)/(cell_precision+cell_recall)\n",
    "    \n",
    "    headers = [\"Metric\", \"Row\", \"Column\", \"Cell\"]\n",
    "    table = [\n",
    "        [\"Precision\", f\"{row_precision:.4f}\", f\"{column_precision:.4f}\", f\"{cell_precision:.4f}\"],\n",
    "        [\"Recall\", f\"{row_recall:.4f}\", f\"{column_recall:.4f}\", f\"{cell_recall:.4f}\"],\n",
    "        [\"F1 Score\", f\"{row_f1:.4f}\", f\"{column_f1:.4f}\", f\"{cell_f1:.4f}\"]\n",
    "    ]\n",
    "    print(f\"Table EM: {exact_match_score:.4f}\")\n",
    "    print(tabulate(table, headers=headers, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7554b90f-3f29-45d3-b031-a4f306acfa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_result(datas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097ef2cf-fda4-4790-9e1a-e16a5382ceeb",
   "metadata": {},
   "source": [
    "# SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf148962-b339-4563-806c-5082351351d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read SQL templates\n",
    "prompt_file_name = './prompts/SQL_prompt.json'\n",
    "with open(prompt_file_name, 'r', encoding='utf-8') as f:\n",
    "    templates = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdf47af-6dbd-409b-8c0c-a3b5599e0798",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in tqdm(datas):\n",
    "    query = data['query']\n",
    "    intent = data[\"ICL_pred_intent\"][0]\n",
    "    prompt = ChatPromptTemplate.from_template(templates[intent])\n",
    "    chain = prompt | llm\n",
    "    if '+' in intent:\n",
    "        intent = intent.split('+')\n",
    "    else:\n",
    "        intent = [intent]\n",
    "    if set(intent).issubset(house_sales_field):\n",
    "        dbname = '价格查询'\n",
    "    elif set(intent).issubset(land_sales_field):\n",
    "        dbname = '土地资产'\n",
    "    elif set(intent).issubset(enterprise_sales_field):\n",
    "        dbname = '企业财务'\n",
    "    slots = data['ICL_pred_slots']\n",
    "    pred_table_name = data['bm25_pred_tabel_caption']\n",
    "    response = chain.invoke({\"query\":query, \"intent\":intent, \"slots\":slots, \"table_name\":pred_table_name})\n",
    "    sql_statement = response.content\n",
    "    data['predict_SQL'] = sql_statement\n",
    "    executor = PostgresQueryExecutor(database=dbname)\n",
    "    try:\n",
    "        table_heads, table_results = executor.execute_sql(sql_statement)\n",
    "        data['predict_SQL_answer'] = table_results\n",
    "    except:\n",
    "        data['predict_SQL_answer'] = 'error'\n",
    "    executor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673d2005-6b9f-480c-b36b-4e92578c2dda",
   "metadata": {},
   "source": [
    "## Calculate metrics for SQL results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b866cf4-bc2c-4f93-be34-bb7393704c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_at_k(n, c, k):\n",
    "    \"\"\"\n",
    "    :param n: total number of samples\n",
    "    :param c: number of correct samples\n",
    "    :param k: k in pass@$k$\n",
    "    \"\"\"\n",
    "    if n - c < k:\n",
    "        return 1.0\n",
    "    return 1.0 - np.prod(1.0 - k /np.arange(n - c + 1, n + 1))\n",
    "\n",
    "def calculate_average_pass1(data):\n",
    "    total_pass1 = sum(item['pass1'] for item in data.values())\n",
    "    count = len(data)\n",
    "    if count == 0:\n",
    "        return 0  \n",
    "    return total_pass1 / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83878e41-373c-4604-88c1-22aacc7f91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "uuids = {}\n",
    "for data in datas:\n",
    "    table_results = data['predict_SQL_answer']\n",
    "    true_SQL_answer = data['SQL_answer']\n",
    "    if table_results is not None and all(isinstance(i, list) for i in table_results):\n",
    "        table_results = [tuple(sublist) for sublist in table_results]\n",
    "    if true_SQL_answer is not None and all(isinstance(i, list) for i in true_SQL_answer):\n",
    "        true_SQL_answer = [tuple(sublist) for sublist in true_SQL_answer]\n",
    "    if table_results != None and set(table_results) == set(true_SQL_answer) and len(table_results) == len(true_SQL_answer):\n",
    "        data['predict_correctness'] = True\n",
    "    else:\n",
    "        data['predict_correctness'] = False\n",
    "    if f'{i}' not in uuids.keys():\n",
    "        uuids[f'{i}'] = []\n",
    "    uuids[f'{i}'].append(data['predict_correctness'])\n",
    "\n",
    "for key in uuids.keys():\n",
    "    c = sum(uuids[key])\n",
    "    n = len(uuids[key])\n",
    "    uuids[key] = {'c': c, 'n': n}\n",
    "    uuids[key]['pass1'] = pass_at_k(n = uuids[key]['n'], c = uuids[key]['c'],k=1)\n",
    "print(f'{len(datas)}')\n",
    "print(f'pass@1：{calculate_average_pass1(uuids)}')\n",
    "\n",
    "preds = []\n",
    "trues = []\n",
    "unexecutable_sql = 0\n",
    "all_sql = 0\n",
    "for data in tqdm(datas):\n",
    "    if data['predict_SQL_answer'] == None:\n",
    "        data['predict_SQL_answer'] = []\n",
    "        unexecutable_sql += 1\n",
    "    preds.append(data['predict_SQL_answer'])\n",
    "    trues.append(data['SQL_answer'])\n",
    "    all_sql += 1\n",
    "\n",
    "ECR = (all_sql - unexecutable_sql)/all_sql\n",
    "\n",
    "\n",
    "print(f'ECR:{ECR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16892ee-b112-4241-9c9f-2b6ae711d298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
