{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22c8ad1-04af-4d78-849c-a2e65f11a64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "from torch.optim import Adam\n",
    "from ipywidgets import FloatProgress\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import re\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "import json\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import re\n",
    "from rank_bm25 import BM25Okapi\n",
    "import jieba\n",
    "import math\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf2d3e0-98b5-4252-9347-f13fa8b296d7",
   "metadata": {},
   "source": [
    "#### Please modify this section to include a usable API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e293a6-f874-4ff3-be94-fdaa41bcb005",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_base_url = \"http://change me\"\n",
    "model_name = 'change me'\n",
    "api_key = 'change me'\n",
    "llm = ChatOpenAI(model_name=model_name, openai_api_key=api_key, base_url=custom_base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a136c1f7-c68c-4eed-a151-c116f0b1946f",
   "metadata": {},
   "source": [
    "# SR module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3d45cb-2079-426d-879c-5cfb8b42d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the generated table names in a JSON file.\n",
    "class PredictResultStorage:\n",
    "    def __init__(self, file_name='testdata.json'):\n",
    "        self.current_data = {}\n",
    "        self.file_name = file_name\n",
    "\n",
    "    def set_predict_tabel_name(self, predict_tabel_name):\n",
    "        self.current_data[\"predict_tabel_name\"] = predict_tabel_name\n",
    "        \n",
    "    def set_true_tabel_name(self, true_tabel_name):\n",
    "        self.current_data[\"true_tabel_name\"] = true_tabel_name\n",
    "\n",
    "    def set_uuid(self, uuid):\n",
    "        self.current_data[\"uuid\"] = uuid\n",
    "\n",
    "    def save_data(self):\n",
    "        if os.path.exists(self.file_name):\n",
    "            with open(self.file_name, 'r+') as f:\n",
    "                data = json.load(f)\n",
    "                data.append(self.current_data)\n",
    "                f.seek(0)\n",
    "                json.dump(data, f, indent=4)\n",
    "        else:\n",
    "            with open(self.file_name, 'w') as f:\n",
    "                json.dump([self.current_data], f, indent=4)\n",
    "        # Clear current_data to prepare for storing the next piece of data.\n",
    "        self.current_data = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fb41c8-a161-441a-b94f-5a6cfe48a043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read templates\n",
    "prompt_file_name = './prompts/retrival_prompt.json'\n",
    "with open(prompt_file_name, 'r', encoding='utf-8') as f:\n",
    "    templates = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36eb740-9eaa-41ab-a0be-ebe0573fa9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = './results/test-with-BERT_pred_intent+slots.json'\n",
    "with open(json_file, 'r', encoding='utf-8') as f:\n",
    "    datas = json.load(f)\n",
    "\n",
    "for data in tqdm(datas):\n",
    "    try:\n",
    "        query = data['query']\n",
    "        intent = data['BERT_pred_intent']\n",
    "        slots = data['BERT_pred_slots']\n",
    "        prompt = ChatPromptTemplate.from_template(templates[intent])\n",
    "        chain = prompt | llm\n",
    "        response = chain.invoke({\"input_query\":query,\"intent\":intent, \"slots\":slots})\n",
    "        data['predict_tabel_caption'] = response.content\n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"An unexpected interruption occurred at record {i}.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841029bc-b373-4e1e-b6d0-60be98a5834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the table names and store them as a vector in memory.\n",
    "table_names_file = './table_names.json'\n",
    "with open(table_names_file, 'r', encoding='utf-8') as f:\n",
    "    name_data = json.load(f)\n",
    "# Corpus\n",
    "corpus = name_data\n",
    "tokenized_corpus = [list(jieba.cut_for_search(doc)) for doc in corpus]\n",
    "# Build the index\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710a01b2-da0f-493c-ab9f-6abffb514183",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = []\n",
    "bm_25s = []\n",
    "trues = []\n",
    "\n",
    "for data in tqdm(datas):\n",
    "    # Perform preliminary cleaning on content generated by the LLM\n",
    "    if '：' in data['predict_tabel_caption'] or ':' in data['predict_tabel_caption']:\n",
    "        #print(data['predict_tabel_name'])\n",
    "        if '：' in data['predict_tabel_caption']:\n",
    "            idx = data['predict_tabel_caption'].rfind('：')\n",
    "        if ':' in data['predict_tabel_caption']:\n",
    "            idx = data['predict_tabel_caption'].rfind(':')\n",
    "        data['predict_tabel_caption'] = data['predict_tabel_caption'][idx+1:]\n",
    "    if ',' in data['predict_tabel_caption'] and '[' in data['predict_tabel_caption']:\n",
    "        #print(data['predict_tabel_name'])\n",
    "        #print('%%%%%%%%%%')\n",
    "        predict = data['predict_tabel_caption'].split(',')\n",
    "        for pred in predict:\n",
    "            pred = pred.replace(\"[\", \"\")\n",
    "            pred = pred.replace(\"]\", \"\")\n",
    "            pred = pred.replace(\"'\", \"\")\n",
    "            pred = pred.replace('\"', '')\n",
    "    else:\n",
    "        predict = data['predict_tabel_caption']\n",
    "        predict = predict.strip(\"[]'\\\"\")\n",
    "        if ',' in predict:\n",
    "            predict = predict.split(',')\n",
    "    # Remove the spaces\n",
    "    if isinstance(predict, type([])):\n",
    "        bm_25 = predict.copy()\n",
    "        for i,pred in enumerate(predict):\n",
    "            pred = pred.replace(\" \", \"\")\n",
    "            pred = pred.replace(\"[\", \"\")\n",
    "            pred = pred.replace(\"]\", \"\")\n",
    "            pred = pred.replace('\\\\', \"\")\n",
    "            pred = pred.replace(\"\\\"\", \"\")\n",
    "            pred = pred.replace(\"\\'\", \"\")\n",
    "            pred = pred.replace(\"\\n\", \"\")\n",
    "            predict[i] = pred\n",
    "            # result = retriever.invoke(pred)\n",
    "            # Retrieve BM25 matching results\n",
    "            tokenized_query = list(jieba.cut_for_search(pred))\n",
    "            result = bm25.get_top_n(tokenized_query, corpus, n=1)\n",
    "            # result = [doc.page_content for doc in result]\n",
    "            bm_25[i] = result[0]\n",
    "    if isinstance(predict, type([])):\n",
    "        predict = list(set(predict))\n",
    "        bm_25 = list(set(bm_25))\n",
    "            \n",
    "    elif isinstance(predict, type('')):\n",
    "        pred = predict\n",
    "        pred = pred.replace(\" \", \"\")\n",
    "        pred = pred.replace(\"[\", \"\")\n",
    "        pred = pred.replace(\"]\", \"\")\n",
    "        pred = pred.replace('\\\\', \"\")\n",
    "        pred = pred.replace(\"\\\"\", \"\")\n",
    "        pred = pred.replace(\"\\'\", \"\")\n",
    "        pred = pred.replace(\"\\n\", \"\")\n",
    "        predict = pred\n",
    "        #result = retriever.invoke(pred)\n",
    "        tokenized_query = list(jieba.cut_for_search(pred))\n",
    "        result = bm25.get_top_n(tokenized_query, corpus, n=1)\n",
    "        # result = [doc.page_content for doc in result]\n",
    "        bm_25 = result[0]\n",
    "    # Extract Chinese characters and create a new list\n",
    "    #predict = [re.sub(r'[^\\w\\s\\u4e00-\\u9fff]', '', s) for s in predict]\n",
    "    predicts.append(predict)\n",
    "    bm_25s.append(bm_25)\n",
    "    true = data['table_caption_label']\n",
    "    trues.append(true)\n",
    "    data['bm25_pred_tabel_caption'] = bm_25\n",
    "print(f'tabel_caption score：{metric_compute(trues, bm_25s)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619d6290-c24e-4745-9e72-1b94964d45dd",
   "metadata": {},
   "source": [
    "# SFA module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b400f63-bf6e-487a-bdea-dd8cfa8e836a",
   "metadata": {},
   "source": [
    "## Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524d1a26-417a-4b14-9bd0-3f5c36adc2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './prompts/first_prompts.json'\n",
    "with open(file_name, 'r', encoding='utf-8') as f:\n",
    "    first_templates = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e410ce46-08f3-4378-aef4-eb7d7a071376",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './prompts/second_prompts.json'\n",
    "with open(file_name, 'r', encoding='utf-8') as f:\n",
    "    second_templates = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db982f8-e6af-4280-8adf-ac0529ac7258",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_tables_json_file = '../database/markdown_tables/all_markdown_table.json'\n",
    "with open(md_tables_json_file, 'r', encoding='utf-8') as f:\n",
    "    md_table_datas = json.load(f)\n",
    "\n",
    "\n",
    "for data in datas:\n",
    "    names = data['bm25_pred_tabel_caption']\n",
    "    if isinstance(names, type('')):\n",
    "        names = [names]\n",
    "    all_table = ''\n",
    "    for name in names:\n",
    "        for md_table_data in md_table_datas:\n",
    "            if md_table_data['table_name'] == name:\n",
    "                table = md_table_data['markdown_table']\n",
    "                all_table = all_table + ' ' + table\n",
    "    data['pred_markdown_table'] = all_table[1:]\n",
    "\n",
    "for data in tqdm(datas):\n",
    "    try:\n",
    "        query = data['query']\n",
    "        intent = data['BERT_pred_intent']\n",
    "        template1 = first_templates[data['BERT_pred_intent']]\n",
    "        template2 = second_templates[data['BERT_pred_intent']]\n",
    "        prompt1 = ChatPromptTemplate.from_template(template1)\n",
    "        chain1 = prompt1 | llm\n",
    "        prompt2 = ChatPromptTemplate.from_template(template2)\n",
    "        chain2 = prompt2 | llm\n",
    "        if '+' in data['BERT_pred_intent']:\n",
    "            intent = data['BERT_pred_intent'].split('+')\n",
    "        else:\n",
    "            intent = [data['BERT_pred_intent']]\n",
    "        slots = data['BERT_pred_slots']\n",
    "        input_markdown_table = data[\"pred_markdown_table\"]\n",
    "        \n",
    "        response1 = chain1.invoke({\"input_query\":query,\"intent\":intent,\"slots\":slots,\"table\":input_markdown_table})\n",
    "        # print(response.content)\n",
    "        simple_table = response1.content\n",
    "        response2 = chain2.invoke({\"input_query\":query,\"intent\":intent,\"slots\":slots,\"table\":simple_table})\n",
    "        data['predict_markdown_answer'] = response2.content\n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"An unexpected interruption occurred at record {i}.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750e4ebf-5840-49f0-8bee-651b2e98562f",
   "metadata": {},
   "source": [
    "## Calculate metrics for Markdown results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8258200-a506-4b87-8fe0-20886757af60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import json\n",
    "import re\n",
    "import argparse\n",
    "from collections import Counter, defaultdict\n",
    "from rouge_score import rouge_scorer, scoring\n",
    "from datasets import load_from_disk\n",
    "from evaluate import load as evaluate_load\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2269946e-4ec3-4a67-b5be-cbe707d110c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rows_columns_cells(line):\n",
    "    line=line.lower()\n",
    "    if \"col :\" in line:\n",
    "        line=line.split(\"col :\")[1].strip()\n",
    "    lines=re.split(\"\\s+row\\s+[0-9]+\\s+:\\s+\",line)\n",
    "    rows=[\" | \".join([cell.strip() for cell in row.split(\"|\")]) for row in lines[1:]]\n",
    "    cells=[cell.strip() for row in lines[1:] for cell in row.split(\"|\")]\n",
    "    columns=[\" | \".join([elem.strip() for elem in elems]) for elems in list(zip(*[row.split(\" | \") for row in lines]))]\n",
    "    return rows, columns,cells\n",
    "\n",
    "def get_correct_total_prediction(target_str, pred_str):\n",
    "    target_rows, target_columns, target_cells = get_rows_columns_cells(target_str)\n",
    "    prediction_rows, prediction_columns, prediction_cells = get_rows_columns_cells(pred_str)\n",
    "    common_rows = Counter(target_rows) & Counter(prediction_rows)\n",
    "    common_rows = list(common_rows.elements())\n",
    "    common_columns = Counter(target_columns) & Counter(prediction_columns)\n",
    "    common_columns = list(common_columns.elements())\n",
    "    common_cells = Counter(target_cells) & Counter(prediction_cells)\n",
    "    common_cells = list(common_cells.elements())\n",
    "    return {\"target_rows\":target_rows,\n",
    "          \"target_columns\":target_columns,\n",
    "          \"target_cells\":target_cells,\n",
    "          \"pred_rows\":prediction_rows,\n",
    "          \"pred_columns\":prediction_columns,\n",
    "          \"pred_cells\":prediction_cells,\n",
    "          \"correct_rows\":common_rows,\n",
    "          \"correct_columns\":common_columns,\n",
    "          \"correct_cells\":common_cells}\n",
    "\n",
    "def compute_result(results: list):\n",
    "    total_columns_in_dataset = 0\n",
    "    total_rows_in_dataset = 0\n",
    "    total_cells_in_dataset = 0\n",
    "    total_correct_rows = 0\n",
    "    total_correct_columns = 0\n",
    "    total_correct_cells = 0\n",
    "    total_prediced_rows_in_dataset = 0\n",
    "    total_predicted_columns_in_dataset = 0\n",
    "    total_predicted_cells_in_dataset = 0\n",
    "    preds = []\n",
    "    trues = []\n",
    "    for result in results:\n",
    "        true = result['markdown_answer']\n",
    "        pred = result['predict_markdown_answer']\n",
    "        trues.append(true)\n",
    "        preds.append(pred)\n",
    "        statistics = get_correct_total_prediction(true, pred)\n",
    "        total_columns_in_dataset += len(statistics['target_columns'])\n",
    "        total_rows_in_dataset += len(statistics['target_rows'])\n",
    "        total_cells_in_dataset += len(statistics['target_cells'])\n",
    "        total_correct_columns += len(statistics['correct_columns'])\n",
    "        total_correct_rows += len(statistics['correct_rows'])\n",
    "        total_correct_cells += len(statistics['correct_cells'])\n",
    "        total_prediced_rows_in_dataset += len(statistics['pred_rows'])\n",
    "        total_predicted_columns_in_dataset += len(statistics['pred_columns'])\n",
    "        total_predicted_cells_in_dataset += len(statistics['pred_cells'])\n",
    "    \n",
    "    exact_match_metric = evaluate_load(\"exact_match\")\n",
    "    row_precision = total_correct_rows / total_prediced_rows_in_dataset\n",
    "    row_recall = total_correct_rows / total_rows_in_dataset\n",
    "    row_f1 = (2*row_precision*row_recall)/(row_precision+row_recall)\n",
    "    exact_match_score = exact_match_metric.compute(predictions=preds, references=trues)['exact_match']\n",
    "    column_precision = total_correct_columns / total_predicted_columns_in_dataset\n",
    "    column_recall = total_correct_columns / total_columns_in_dataset\n",
    "    column_f1 = (2*column_precision*column_recall)/(column_precision+column_recall)\n",
    "    cell_precision = total_correct_cells / total_predicted_cells_in_dataset\n",
    "    cell_recall = total_correct_cells / total_cells_in_dataset\n",
    "    cell_f1 = (2*cell_precision*cell_recall)/(cell_precision+cell_recall)\n",
    "    \n",
    "    headers = [\"Metric\", \"Row\", \"Column\", \"Cell\"]\n",
    "    table = [\n",
    "        [\"Precision\", f\"{row_precision:.4f}\", f\"{column_precision:.4f}\", f\"{cell_precision:.4f}\"],\n",
    "        [\"Recall\", f\"{row_recall:.4f}\", f\"{column_recall:.4f}\", f\"{cell_recall:.4f}\"],\n",
    "        [\"F1 Score\", f\"{row_f1:.4f}\", f\"{column_f1:.4f}\", f\"{cell_f1:.4f}\"]\n",
    "    ]\n",
    "    print(f\"Table EM: {exact_match_score:.4f}\")\n",
    "    print(tabulate(table, headers=headers, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07767434-fb24-4870-b576-0fa7925176b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_result(datas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f80240-5c3a-4aee-935b-ab683d875190",
   "metadata": {},
   "source": [
    "## SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66138590-4497-473c-bcbf-a508cb4eca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read SQL templates\n",
    "prompt_file_name = './prompts/SQL_prompt.json'\n",
    "with open(prompt_file_name, 'r', encoding='utf-8') as f:\n",
    "    templates = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e152924-3975-4fb3-803d-8aaa9a767eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in tqdm(datas):\n",
    "    query = data['query']\n",
    "    intent = data[\"BERT_pred_intent\"]\n",
    "    prompt = ChatPromptTemplate.from_template(templates[intent])\n",
    "    chain = prompt | llm\n",
    "    if '+' in data['BERT_pred_intent']:\n",
    "        intent = data['BERT_pred_intent'].split('+')\n",
    "    else:\n",
    "        intent = [data['BERT_pred_intent']]\n",
    "    if set(intent).issubset(house_sales_field):\n",
    "        dbname = '价格查询'\n",
    "    elif set(intent).issubset(land_sales_field):\n",
    "        dbname = '土地资产'\n",
    "    elif set(intent).issubset(enterprise_sales_field):\n",
    "        dbname = '企业财务'\n",
    "    slots = data['BERT_pred_slots']\n",
    "    pred_table_name = data['bm25_pred_tabel_caption']\n",
    "    response = chain.invoke({\"query\":query, \"intent\":intent, \"slots\":slots, \"table_name\":pred_table_name})\n",
    "    sql_statement = response.content\n",
    "    data['predict_SQL'] = sql_statement\n",
    "    executor = PostgresQueryExecutor(database=dbname)\n",
    "    try:\n",
    "        table_heads, table_results = executor.execute_sql(sql_statement)\n",
    "        data['predict_SQL_answer'] = table_results\n",
    "    except:\n",
    "        data['predict_SQL_answer'] = 'error'\n",
    "    executor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ac7d3f-6d8c-4a3c-abd2-3ac9ae4334e8",
   "metadata": {},
   "source": [
    "## Calculate metrics for SQL results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67848c0e-ebdd-4cc9-8eb9-2b622a2bf3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_at_k(n, c, k):\n",
    "    \"\"\"\n",
    "    :param n: total number of samples\n",
    "    :param c: number of correct samples\n",
    "    :param k: k in pass@$k$\n",
    "    \"\"\"\n",
    "    if n - c < k:\n",
    "        return 1.0\n",
    "    return 1.0 - np.prod(1.0 - k /np.arange(n - c + 1, n + 1))\n",
    "\n",
    "def calculate_average_pass1(data):\n",
    "    total_pass1 = sum(item['pass1'] for item in data.values())\n",
    "    count = len(data)\n",
    "    if count == 0:\n",
    "        return 0 \n",
    "    return total_pass1 / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c7ab67-eb63-4235-9681-a2c0ba4e3afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "uuids = {}\n",
    "for data in datas:\n",
    "    table_results = data['predict_SQL_answer']\n",
    "    true_SQL_answer = data['SQL_answer']\n",
    "    if table_results is not None and all(isinstance(i, list) for i in table_results):\n",
    "        table_results = [tuple(sublist) for sublist in table_results]\n",
    "    if true_SQL_answer is not None and all(isinstance(i, list) for i in true_SQL_answer):\n",
    "        true_SQL_answer = [tuple(sublist) for sublist in true_SQL_answer]\n",
    "    if table_results != None and set(table_results) == set(true_SQL_answer) and len(table_results) == len(true_SQL_answer):\n",
    "        data['predict_correctness'] = True\n",
    "    else:\n",
    "        data['predict_correctness'] = False\n",
    "    if f'{i}' not in uuids.keys():\n",
    "        uuids[f'{i}'] = []\n",
    "    uuids[f'{i}'].append(data['predict_correctness'])\n",
    "\n",
    "for key in uuids.keys():\n",
    "    c = sum(uuids[key])\n",
    "    n = len(uuids[key])\n",
    "    uuids[key] = {'c': c, 'n': n}\n",
    "    uuids[key]['pass1'] = pass_at_k(n = uuids[key]['n'], c = uuids[key]['c'],k=1)\n",
    "print(f'{len(datas)}')\n",
    "print(f'pass@1：{calculate_average_pass1(uuids)}')\n",
    "\n",
    "preds = []\n",
    "trues = []\n",
    "unexecutable_sql = 0\n",
    "all_sql = 0\n",
    "for data in tqdm(datas):\n",
    "    if data['predict_SQL_answer'] == None:\n",
    "        data['predict_SQL_answer'] = []\n",
    "        unexecutable_sql += 1\n",
    "    preds.append(data['predict_SQL_answer'])\n",
    "    trues.append(data['SQL_answer'])\n",
    "    all_sql += 1\n",
    "\n",
    "ECR = (all_sql - unexecutable_sql)/all_sql\n",
    "\n",
    "\n",
    "print(f'ECR:{ECR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6431d06a-de76-43ff-ab3c-4cd1355b28e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbbf13a-161a-4b45-b7da-abf11d3ac728",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
